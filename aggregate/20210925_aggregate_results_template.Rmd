
---
title: "Aggregate NinjaMap Data"
author: "Sunit"
date: "02/18/2021"
updated: "09/25/2021"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("tidyverse")
#devtools::install_github("tidyverse/tidyverse")
library(tidyverse)
library(fs)
library(ggbeeswarm)
library(lubridate)
library(zip)
nm_basedir = '/Users/xdmeng/project/R/ninjaMap/Alice'
source(paste(nm_basedir,'aggregate_data_util_functions.R', sep='/'))
```

# Adjust location for the utility script
```{r}
```

# S3 path should be in the format `<s3_nm_base_path>/<db_name>/<study_name>`
```{r}
s3_nm_base_path = 's3://czbiohub-microbiome/Synthetic_Community/NinjaMap_Narrow/Index'
db_name = 'db_SCv2_4' # should be same as on S3
#study_name_prefix = '210709_NB501938_0237_AHCVGYBGXJ' # also used as output prefix
study_name ='mbfv1_sentinel'
```

# Adjust local output location and prefix (time_stamp)
```{r}
time_stamp = now() %>% format("%Y%m%d")
workdir = '/Users/xdmeng/project/work/Alice'
#print(paste0("Current workdir: ", workdir))
```

## Setup Project paths
```{r}
local_base = paste(workdir,db_name, sep='/')
#s3_base = paste(s3_nm_base_path,db_name,study_name_prefix, sep="/")
s3_base = paste0(s3_nm_base_path,"/",db_name)
#s3_base = 's3://czbiohub-microbiome/Synthetic_Community/NinjaMap_Narrow/Index/db_Min1_1/210616_A00111_0743_BHCMWNDSX2'
```

# DB Metadata
```{r read_metadata, include=FALSE}
# # generate_report.py output
# db_meta = read_csv('/Users/sunit.jain/Research/NinjaMap/Database/SCv1_2/SCv1_2.report.csv')
#
# # from "Sequencing" tab of https://docs.google.com/spreadsheets/d/1rZUfisKKmPfLkZP1eEsNFyCKUyMm6nHQQAhNxnJJYXE/edit#gid=280797532
# strain_isolates_names_map = read_csv('/Users/sunit.jain/Research/Alice/in_vitro/SEEDFILES/StrainIsolates/shared/20200506_all_strainIso_sequencing_efforts.csv') %>%
#   select(sampleName,sample_id,Run) %>%
#   distinct()
```

# Setup local output dir strucutre
```{r}
study_s3_base = paste(s3_base,study_name, sep='/')
study_output_base = make_dir(paste(local_base,study_name, sep = '/'))
study_analysis_path = make_dir(paste(study_output_base,"analysis", sep = '/'))
study_raw_output_path = make_dir(paste(study_output_base,"raw_output", sep = '/'))
study_figures_path = make_dir(paste(study_output_base,"figures", sep = '/'))
```

# Download from S3
```{r}
# download_all_runs(runs_list,study_raw_output_path,study_s3_base)
download_from_s3(study_raw_output_path, study_s3_base)
```

## Aggregate all the outputs, by stacking.
```{r}
strain_dropouts = suppressMessages(aggregate_abundance_data(parent_path = study_raw_output_path))
strain_read_stats = suppressMessages(aggregate_read_stats(parent_path = study_raw_output_path))

host_contamination_stats = suppressMessages(aggregate_host_stats(parent_path = study_raw_output_path))
```

## Clean up and compress (OPTIONAL)
```{r}
zipr(paste0(study_raw_output_path,".zip"), study_raw_output_path)
dir_delete(study_raw_output_path)
```


## Split outputs by dimension
```{r}
sd_read_fraction_matrix = strain_dropouts %>%
  select(sample_id, Strain_Name, Read_Fraction) %>%
  group_by(Strain_Name) %>%
  spread(sample_id, Read_Fraction)

sd_percent_cov_matrix = strain_dropouts %>%
  select(sample_id, Strain_Name, Percent_Coverage) %>%
  group_by(Strain_Name) %>%
  spread(sample_id, Percent_Coverage)

sd_cov_depth_matrix = strain_dropouts %>%
  select(sample_id, Strain_Name, Coverage_Depth) %>%
  group_by(Strain_Name) %>%
  spread(sample_id, Coverage_Depth)
```

# Save files
```{r}
strain_dropouts %>%
  write_csv(paste0(study_analysis_path,'/',time_stamp,"_",study_name,".long.csv"),append = FALSE,col_names = TRUE)
strain_read_stats %>%
  write_csv(paste0(study_analysis_path,'/',time_stamp,"_",study_name,".read_stats.csv"),append = FALSE,col_names = TRUE)

sd_read_fraction_matrix %>%
  write_csv(paste0(study_analysis_path,'/',time_stamp,"_",study_name,".readFraction.csv"),append = FALSE,col_names = TRUE)
sd_percent_cov_matrix %>%
  write_csv(paste0(study_analysis_path,'/',time_stamp,"_",study_name,".percCoverage.csv"),append = FALSE,col_names = TRUE)
sd_cov_depth_matrix %>%
  write_csv(paste0(study_analysis_path,'/',time_stamp,"_",study_name,".covDepth.csv"),append = FALSE,col_names = TRUE)

host_contamination_stats %>%
  write_csv(paste0(study_analysis_path,'/',time_stamp,"_",study_name,".host_contaminants.csv"),append = FALSE,col_names = TRUE)
```


```{r}
# db_meta %>%
#   anti_join(., sd_cov_depth_matrix, by = c("bin_name" = "Strain_Name")) %>%
#   select(bin_name)
```

## Plots
```{r}
fragments_stats_df = aggregate_fragment_stats(strain_read_stats, how="all")
```

### Waffle Plots

#### Median across all Samples

```{r}
waffle_df = strain_read_stats %>%
  process_fragment_stats() %>%
  summarize_stats_by_steps()

sum(waffle_df$values)
```

```{r}
waffle_df %>%
  waffle_plot(title = "NinjaMap Read Fate", subtitle = "Median across all samples")
ggsave(paste(study_figures_path,"read_fates.waffle_plot.eps", sep="/"),device = "eps",width = 11,height = 8.5,units = "in", dpi = "retina")
```

#### By Sample
```{r}
library(foreach)
foreach(sample_name=unique(strain_read_stats$sample_id)) %do% {
  p = NULL
  print(sample_name)
  # exclude specific samples
  if (sample_name != "Blank_S28" ) {     #&& sample_name != "Extraction_control") {
   
    p = strain_read_stats %>%
      filter(sample_id == sample_name) %>%
      process_fragment_stats() %>%
      summarize_stats_by_steps() %>%
      waffle_plot(title = "NinjaMap Read Fate", subtitle = paste0("Sample: ",sample_name))
  
    ggsave(plot = p,
           filename = paste0(study_figures_path,"/",sample_name,".read_fates.waffle_plot.eps"),
           device = "eps",
           width = 11,
           height = 8.5,
           units = "in",
           dpi = "retina")
  }
}
```


```{r}
plot_fragment_stats(fragments_stats_df)
ggsave(paste(study_figures_path,"fragment_stats.pdf", sep="/"), height = 12, width = 16, units = "in",dpi = "retina")
```

```{r}
aggregate_fragment_stats(strain_read_stats, how="post_qc") %>%
  plot_fragment_stats()
ggsave(paste(study_figures_path,"fragment_stats.post_qc.pdf", sep="/"), height = 12, width = 16, units = "in",dpi = "retina")
```

```{r}
strain_dropouts %>%
    mutate(formatted_name = sample_id) %>%
  brian_plot(title = "Strain abundance by Sample")+
  geom_point(aes(color=Strain_Name), show.legend = FALSE)+
  geom_line(aes(group=Strain_Name), alpha=0.1,show.legend = FALSE)
ggsave(paste(study_figures_path,"brian_plot.basic.pdf", sep="/"), height = 12, width = 16, units = "in",dpi = "retina")
```
```{r}

# host_contamination_stats header
#sample_id,Host_Contaminant,Total_mapped_paired_reads,"Mapped_Paired_rate(%)  select(starts_with('Mapped_Paired_rate'))

# Rename the column header
names(host_contamination_stats)[4] <- "Mapped_Paired_rate"

host_contamination_stats %>%
ggplot()+
      geom_col(aes(sample_id, Total_mapped_paired_reads, fill=Host_Contaminant), position="dodge") +
      geom_line(aes(x=sample_id, y=Mapped_Paired_rate), size = 1.5, color="blue", group = 1) +
        scale_y_continuous(sec.axis = sec_axis(~./10000,labels = scales::percent, name ="Percentage"))+
  labs(title="Host Contaminant Detection", x="Samples", y= "Contamination Redas")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) 

host_contamination_stats %>%
ggplot()+
      geom_col(aes(sample_id, Mapped_Paired_rate, fill=Host_Contaminant), position="dodge") +
  labs(title="Host Contaminant Detection- Sample Mapping Rate", x="Samples", y= "Contamination Percentage")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) 

ggsave(paste(study_figures_path,"Host_Contaminants_stats.pdf", sep="/"), height = 8, width = 12, units = "in",dpi = "retina")   

```